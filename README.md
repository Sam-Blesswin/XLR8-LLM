# LLM From Scratch

Inspired by Andrej Karpathy's lectures and repos, this repository is dedicated to building a deep understanding of large language models (LLMs) from the ground up.

## Goals

* Explore the core building blocks of LLMs
* Experiment with training, optimization, and fine-tuning techniques
* Develop intuition through hands-on implementation

## Topics

* Tokenization & embeddings
* Transformers & attention mechanisms
* Training from scratch
* Fine-tuning on custom datasets
* Performance optimization

